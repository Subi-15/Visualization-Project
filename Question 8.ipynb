{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 8**\n",
        "Convert an object detection model into a quantized format using any library of your\n",
        "choice (10 pts)\n",
        "\n",
        "\n",
        "1.  Run inference with the quantized model (5 pts)\n",
        "2.  Find the difference in accuracy between the quantized model and the fp32\n",
        "model (10pts)\n"
      ],
      "metadata": {
        "id": "dHSECmSW_XpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary Libraries"
      ],
      "metadata": {
        "id": "5dQmbtNB_xW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "metadata": {
        "id": "qJJp1Y1vOFcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "MNIKqws8OSSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset** : Mnist Digit recognisation dataset"
      ],
      "metadata": {
        "id": "MA-kDrnu_7M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Network (CNN) for MNIST Digit Classification**"
      ],
      "metadata": {
        "id": "QaBs5ClQBGVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vzv0gAONjiP",
        "outputId": "2c97f1cb-4192-4fe9-d5b7-3e39d8310e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1688/1688 [==============================] - 20s 12ms/step - loss: 0.2884 - accuracy: 0.9202 - val_loss: 0.1101 - val_accuracy: 0.9712\n",
            "1875/1875 - 9s - loss: 0.1257 - accuracy: 0.9661 - 9s/epoch - 5ms/step\n",
            "\n",
            "Training Accuracy: 0.9660500288009644\n",
            "Validation Accuracy: 0.9711666703224182\n"
          ]
        }
      ],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history= model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  validation_split=0.1,\n",
        ")\n",
        "train_loss, train_accuracy = model.evaluate(train_images, train_labels, verbose=2)\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy}\")\n",
        "\n",
        "# Print the validation accuracy (if validation data is available)\n",
        "if 'val_accuracy' in history.history:\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  A Sequential model is defined with an input layer, reshaping for compatibility with Conv2D layer, a convolutional layer with 12 filters and ReLU activation, a max-pooling layer, and a flattening layer, followed by a dense layer with 10 output units.\n",
        "2.  The model is compiled using the Adam optimizer and sparse categorical crossentropy loss for digit classification.\n",
        "Training is performed on the training set with one epoch and a validation split of 10%.\n",
        "3.  Training accuracy is evaluated and printed after model training.\n"
      ],
      "metadata": {
        "id": "n1_6PAbdBKNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -q tensorflow\n",
        " !pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9C3OnADOlKa",
        "outputId": "a0aed160-b58a-4a45-b73a-fc7c77adfa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/241.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/241.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os"
      ],
      "metadata": {
        "id": "XMHEF2_WOydJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantization  Training for MNIST Digit Classification**"
      ],
      "metadata": {
        "id": "VMBOqng-Bm-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYpH85-bO25C",
        "outputId": "49521965-33ab-434b-d2bd-cbb4e32937bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLa  (None, 28, 28)            3         \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " quant_reshape_1 (QuantizeW  (None, 28, 28, 1)         1         \n",
            " rapperV2)                                                       \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWr  (None, 26, 26, 12)        147       \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_max_pooling2d_1 (Qua  (None, 13, 13, 12)        1         \n",
            " ntizeWrapperV2)                                                 \n",
            "                                                                 \n",
            " quant_flatten_1 (QuantizeW  (None, 2028)              1         \n",
            " rapperV2)                                                       \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWra  (None, 10)                20295     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20448 (79.88 KB)\n",
            "Trainable params: 20410 (79.73 KB)\n",
            "Non-trainable params: 38 (152.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   The quantize_model function is applied to the previously defined MNIST digit classification model, creating a quantization-aware version (q_aware_model).\n",
        "2.   To enable quantization, the quantized model is recompiled with the same configuration as the original model, including the Adam optimizer and sparse categorical crossentropy loss.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aR0bUbKGBsOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_subset = train_images[0:1000] # out of 60000\n",
        "train_labels_subset = train_labels[0:1000]\n",
        "\n",
        "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
        "                  batch_size=500, epochs=50, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GxM5O_EO_cE",
        "outputId": "95679960-959c-4e95-dde0-8fb992970d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 0.0717 - accuracy: 0.9822 - val_loss: 0.1851 - val_accuracy: 0.9700\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 0.0686 - accuracy: 0.9844 - val_loss: 0.1900 - val_accuracy: 0.9700\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.0648 - accuracy: 0.9856 - val_loss: 0.1948 - val_accuracy: 0.9600\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 0.0623 - accuracy: 0.9867 - val_loss: 0.1868 - val_accuracy: 0.9700\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.0618 - accuracy: 0.9844 - val_loss: 0.1929 - val_accuracy: 0.9600\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 0.0578 - accuracy: 0.9889 - val_loss: 0.1997 - val_accuracy: 0.9600\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 0.0553 - accuracy: 0.9900 - val_loss: 0.2198 - val_accuracy: 0.9400\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 0.0527 - accuracy: 0.9922 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 0.0498 - accuracy: 0.9922 - val_loss: 0.2120 - val_accuracy: 0.9600\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 0.0476 - accuracy: 0.9933 - val_loss: 0.2111 - val_accuracy: 0.9600\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 0.0455 - accuracy: 0.9933 - val_loss: 0.2144 - val_accuracy: 0.9600\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.0436 - accuracy: 0.9944 - val_loss: 0.2185 - val_accuracy: 0.9600\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.0418 - accuracy: 0.9944 - val_loss: 0.2193 - val_accuracy: 0.9600\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.0402 - accuracy: 0.9944 - val_loss: 0.2210 - val_accuracy: 0.9600\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.0384 - accuracy: 0.9944 - val_loss: 0.2232 - val_accuracy: 0.9600\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.0373 - accuracy: 0.9944 - val_loss: 0.2272 - val_accuracy: 0.9600\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.0362 - accuracy: 0.9944 - val_loss: 0.2186 - val_accuracy: 0.9600\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.0349 - accuracy: 0.9944 - val_loss: 0.2208 - val_accuracy: 0.9600\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 0.0338 - accuracy: 0.9956 - val_loss: 0.2341 - val_accuracy: 0.9500\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.0320 - accuracy: 0.9956 - val_loss: 0.2283 - val_accuracy: 0.9600\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 0.0304 - accuracy: 0.9967 - val_loss: 0.2327 - val_accuracy: 0.9600\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 0.0295 - accuracy: 0.9967 - val_loss: 0.2361 - val_accuracy: 0.9600\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 0.0282 - accuracy: 0.9978 - val_loss: 0.2366 - val_accuracy: 0.9600\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 260ms/step - loss: 0.0273 - accuracy: 0.9978 - val_loss: 0.2399 - val_accuracy: 0.9600\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 0.0265 - accuracy: 0.9989 - val_loss: 0.2423 - val_accuracy: 0.9600\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 0.0255 - accuracy: 0.9989 - val_loss: 0.2455 - val_accuracy: 0.9600\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 267ms/step - loss: 0.0247 - accuracy: 0.9989 - val_loss: 0.2469 - val_accuracy: 0.9600\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 209ms/step - loss: 0.0239 - accuracy: 0.9989 - val_loss: 0.2426 - val_accuracy: 0.9600\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 0.0231 - accuracy: 0.9989 - val_loss: 0.2394 - val_accuracy: 0.9700\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 0.0229 - accuracy: 0.9989 - val_loss: 0.2407 - val_accuracy: 0.9600\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 0.0223 - accuracy: 0.9989 - val_loss: 0.2439 - val_accuracy: 0.9600\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 207ms/step - loss: 0.0214 - accuracy: 0.9989 - val_loss: 0.2483 - val_accuracy: 0.9400\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 0.0208 - accuracy: 0.9989 - val_loss: 0.2503 - val_accuracy: 0.9500\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.0202 - accuracy: 0.9989 - val_loss: 0.2526 - val_accuracy: 0.9500\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.0197 - accuracy: 0.9989 - val_loss: 0.2541 - val_accuracy: 0.9500\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.0192 - accuracy: 0.9989 - val_loss: 0.2571 - val_accuracy: 0.9500\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 0.0186 - accuracy: 0.9989 - val_loss: 0.2575 - val_accuracy: 0.9500\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.0181 - accuracy: 0.9989 - val_loss: 0.2612 - val_accuracy: 0.9500\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.0177 - accuracy: 0.9989 - val_loss: 0.2637 - val_accuracy: 0.9500\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.0172 - accuracy: 0.9989 - val_loss: 0.2642 - val_accuracy: 0.9500\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.0168 - accuracy: 0.9989 - val_loss: 0.2646 - val_accuracy: 0.9500\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.0163 - accuracy: 0.9989 - val_loss: 0.2639 - val_accuracy: 0.9500\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 0.0160 - accuracy: 0.9989 - val_loss: 0.2676 - val_accuracy: 0.9500\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.0156 - accuracy: 0.9989 - val_loss: 0.2682 - val_accuracy: 0.9500\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.0153 - accuracy: 0.9989 - val_loss: 0.2698 - val_accuracy: 0.9500\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.0150 - accuracy: 0.9989 - val_loss: 0.2731 - val_accuracy: 0.9500\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.0147 - accuracy: 0.9989 - val_loss: 0.2773 - val_accuracy: 0.9500\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.0143 - accuracy: 0.9989 - val_loss: 0.2774 - val_accuracy: 0.9500\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.0140 - accuracy: 0.9989 - val_loss: 0.2793 - val_accuracy: 0.9500\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 0.0136 - accuracy: 0.9989 - val_loss: 0.2815 - val_accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78c5f62de350>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Printing Accuracy**"
      ],
      "metadata": {
        "id": "doShBkw1CLxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3J25NaxPVOK",
        "outputId": "aed27e02-6eb2-4d28-96e6-b9346cb6759a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.9634000062942505\n",
            "Quant test accuracy: 0.9487000107765198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGUQ-AHVPcCQ",
        "outputId": "b2abcae1-2fb7-4e2d-84b5-1e9311272b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "TLw5Ys4hPxy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLZ2iDkBP30w",
        "outputId": "741d84d1-449c-472d-b5e7-5bdf62633f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.949\n",
            "Quant TF test accuracy: 0.9487000107765198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_difference = train_accuracy - test_accuracy\n"
      ],
      "metadata": {
        "id": "8v4Oyy4xP-QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the difference in accuracy between the quantized model and the fp32 model"
      ],
      "metadata": {
        "id": "mScoCt9PCUtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original Model Accuracy: {train_accuracy}\")\n",
        "print(f\"Quantized Model Accuracy: { test_accuracy}\")\n",
        "print(f\"Accuracy Difference: {accuracy_difference}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElKGyezKSD54",
        "outputId": "89250ee9-1b18-45fa-c2b4-64ffa32a94cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Accuracy: 0.9660500288009644\n",
            "Quantized Model Accuracy: 0.949\n",
            "Accuracy Difference: 0.0170500288009644\n"
          ]
        }
      ]
    }
  ]
}